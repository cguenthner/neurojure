<!DOCTYPE html PUBLIC ""
    "">
<html><head><meta charset="UTF-8" /><title>neurojure.core documentation</title><link rel="stylesheet" type="text/css" href="css/default.css" /><link rel="stylesheet" type="text/css" href="css/highlight.css" /><script type="text/javascript" src="js/highlight.min.js"></script><script type="text/javascript" src="js/jquery.min.js"></script><script type="text/javascript" src="js/page_effects.js"></script><script>hljs.initHighlightingOnLoad();</script></head><body><div id="header"><h2>Generated by <a href="https://github.com/weavejester/codox">Codox</a></h2><h1><a href="index.html"><span class="project-title"><span class="project-name">Neurojure</span> <span class="project-version">0.0.1</span></span></a></h1></div><div class="sidebar primary"><h3 class="no-link"><span class="inner">Project</span></h3><ul class="index-link"><li class="depth-1 "><a href="index.html"><div class="inner">Index</div></a></li></ul><h3 class="no-link"><span class="inner">Namespaces</span></h3><ul><li class="depth-1"><div class="no-link"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>neurojure</span></div></div></li><li class="depth-2 branch current"><a href="neurojure.core.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>core</span></div></a></li><li class="depth-2"><a href="neurojure.senses.html"><div class="inner"><span class="tree"><span class="top"></span><span class="bottom"></span></span><span>senses</span></div></a></li></ul></div><div class="sidebar secondary"><h3><a href="#top"><span class="inner">Public Vars</span></a></h3><ul><li class="depth-1"><a href="neurojure.core.html#var-binary-cross-entropy"><div class="inner"><span>binary-cross-entropy</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-conv2d"><div class="inner"><span>conv2d</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-conv2d-layer"><div class="inner"><span>conv2d-layer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-cross-entropy"><div class="inner"><span>cross-entropy</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-dense"><div class="inner"><span>dense</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-dropout"><div class="inner"><span>dropout</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-evaluate-model"><div class="inner"><span>evaluate-model</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-constants"><div class="inner"><span>get-model-constants</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-data"><div class="inner"><span>get-model-data</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-dataset"><div class="inner"><span>get-model-dataset</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-graph"><div class="inner"><span>get-model-graph</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-input-map"><div class="inner"><span>get-model-input-map</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-optimizer"><div class="inner"><span>get-model-optimizer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-optimizer-options"><div class="inner"><span>get-model-optimizer-options</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-model-parameters"><div class="inner"><span>get-model-parameters</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-get-previous-optimizer-result"><div class="inner"><span>get-previous-optimizer-result</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-gru"><div class="inner"><span>gru</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-logistic"><div class="inner"><span>logistic</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-logistic-binary-classifier"><div class="inner"><span>logistic-binary-classifier</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-binary-classifier-reporter"><div class="inner"><span>make-binary-classifier-reporter</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-constant-initializer"><div class="inner"><span>make-constant-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-fill-initializer"><div class="inner"><span>make-fill-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-he-normal-initializer"><div class="inner"><span>make-he-normal-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-he-uniform-initializer"><div class="inner"><span>make-he-uniform-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-l1-regularizer"><div class="inner"><span>make-l1-regularizer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-l2-regularizer"><div class="inner"><span>make-l2-regularizer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-lecun-normal-initializer"><div class="inner"><span>make-lecun-normal-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-lecun-uniform-initializer"><div class="inner"><span>make-lecun-uniform-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-model"><div class="inner"><span>make-model</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-multiclass-accuracy-reporter"><div class="inner"><span>make-multiclass-accuracy-reporter</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-normal-random-initializer"><div class="inner"><span>make-normal-random-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-truncated-random-initializer"><div class="inner"><span>make-truncated-random-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-uniform-random-initializer"><div class="inner"><span>make-uniform-random-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-variance-scaling-initializer"><div class="inner"><span>make-variance-scaling-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-xavier-normal-initializer"><div class="inner"><span>make-xavier-normal-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-make-xavier-uniform-initializer"><div class="inner"><span>make-xavier-uniform-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-max-pooling2d"><div class="inner"><span>max-pooling2d</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-mean"><div class="inner"><span>mean</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-normalize"><div class="inner"><span>normalize</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-ones-initializer"><div class="inner"><span>ones-initializer</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-recurrent"><div class="inner"><span>recurrent</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-regularize"><div class="inner"><span>regularize</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-relu"><div class="inner"><span>relu</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-reserved-node-names"><div class="inner"><span>reserved-node-names</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-sigmoid-cross-entropy"><div class="inner"><span>sigmoid-cross-entropy</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-softmax"><div class="inner"><span>softmax</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-train-model"><div class="inner"><span>train-model</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-train-model-async"><div class="inner"><span>train-model-async</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-update-model"><div class="inner"><span>update-model</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-update-prev-optimizer-results"><div class="inner"><span>update-prev-optimizer-results</span></div></a></li><li class="depth-1"><a href="neurojure.core.html#var-zeros-initializer"><div class="inner"><span>zeros-initializer</span></div></a></li></ul></div><div class="namespace-docs" id="content"><h1 class="anchor" id="top">neurojure.core</h1><div class="doc"><div class="markdown"></div></div><div class="public anchor" id="var-binary-cross-entropy"><h3>binary-cross-entropy</h3><div class="usage"><code>(binary-cross-entropy predicted actual)</code></div><div class="doc"><div class="markdown"><p>Computes binary cross entropy: <code>-esum(actual * log (predicted + eps) + (1 - actual) * log (1 - predicted + eps)</code>, where <code>esum</code> is the sum over all elements and <code>eps</code> is a small value added for numerical stabilitiy.`</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L751">view source</a></div></div><div class="public anchor" id="var-conv2d"><h3>conv2d</h3><div class="usage"><code>(conv2d nd kernel strides)</code></div><div class="doc"><div class="markdown"><p>Given tensor <code>nd</code> of shape [m, height, width, channels], a <code>kernel</code> of shape [output-chs, kernel-height, kernel-width, input-chs], and a vector of strides like <code>[row-stride,
column-stride]</code>, returns a tensor of shape [m, floor((height - kernel-height + 1) / row-stride), floor(width - kernel-width + 1) / column-stride), output-chs] that is the product of convolving each of m examples with the kernel.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L601">view source</a></div></div><div class="public anchor" id="var-conv2d-layer"><h3>conv2d-layer</h3><div class="usage"><code>(conv2d-layer operand options)</code></div><div class="doc"><div class="markdown"><p>Returns the 2d convolution of <code>operand</code> with kernels of specified properties. <code>options</code> include:</p>
<ul>
  <li><code>:kernel-size</code> (required) - A two-element vector specifying the kernel [height width].</li>
  <li><code>:output-channels</code> (required) - Number of output channels (equal to the number of kernels that will be convolved with <code>operand</code>).</li>
  <li><code>:strides</code> (optional, default [1 1]) - The [vertical horizontal] step sizes to use when sliding the kernel over <code>operand</code>.</li>
  <li><code>:initializer</code> (optional, default xavier normal) - used for both the kernel and the bias if initializers specific to those parameters are not given</li>
  <li><code>:kernel-iniitializer</code> (optional)</li>
  <li><code>:bias-initializer</code> (optional)</li>
  <li><code>:padding</code> (optional) - an argument accepted by <code>pad-with</code>. <code>operand</code> is padded with zeros before convolution.</li>
</ul>
<p>See <code>conv2d</code> for the structures of the input and output tensors.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L675">view source</a></div></div><div class="public anchor" id="var-cross-entropy"><h3>cross-entropy</h3><div class="usage"><code>(cross-entropy predicted actual)</code></div><div class="doc"><div class="markdown"><p>Computes <code>-esum(actual * log (predicted + eps))</code>, where <code>esum</code> is the sum over all elements and <code>eps</code> is a small value added for numerical stabilitiy.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L740">view source</a></div></div><div class="public anchor" id="var-dense"><h3>dense</h3><div class="usage"><code>(dense operand options)</code></div><div class="doc"><div class="markdown"><p>Given an <code>operand</code> matrix of shape [m input-size], computes <code>operand . W + b</code>, where <code>.</code> is matrix multiplication, W is a parameter matrix of shape [input-size units], and b is a parameter matrix of shape [1 units]. Options include:</p>
<ul>
  <li><code>:units</code> (required) - scalar number of ‘units’ to include in the layer</li>
  <li><code>:initializer</code> (optional, default xavier normal) - single initializer for both W and b</li>
  <li><code>:W-intializer</code> (optional) - initializer for W, used instead of that specified in <code>:initializer</code> if  both are provided (default xavier normal)</li>
  <li><code>:b-initializer</code> (optional) - like <code>:W-initializer</code> but for b (default zeros)</li>
  <li><code>:regularizer</code> (optional) - default <code>nil</code></li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L520">view source</a></div></div><div class="public anchor" id="var-dropout"><h3>dropout</h3><div class="usage"><code>(dropout g options)</code></div><div class="doc"><div class="markdown"><p>Masks a fraction of elements in <code>g</code> and scales up remaining elements to maintain a constant sum:</p>
<ul>
  <li><code>:frequency</code> (required) - frequency of elements to drop out (on average)</li>
  <li><code>:exact</code> (default true) - boolean indicating whether scaling of other options in <code>g</code> must be exact  (i.e. proportional to the number of elements actually dropped out, which may vary randomly from run to  run) or approximate (proportional to <code>:frequency</code>). The results for <code>:exact == true</code> and  <code>:exact == false</code> converge when the size of <code>g</code> is large, but the <code>:exact</code> computation is more  expensive.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L432">view source</a></div></div><div class="public anchor" id="var-evaluate-model"><h3>evaluate-model</h3><div class="usage"><code>(evaluate-model model dataset-or-name)</code><code>(evaluate-model model dataset-or-name options)</code></div><div class="doc"><div class="markdown"><p>Returns the result of running <code>model</code> on <code>dataset-or-name</code>. For example, <code>(evaluate-model model :training)</code> will return the model’s output for the <code>:training</code> dataset. Options include:</p>
<ul>
  <li><code>:training</code> - boolean indicating if the <code>:training</code> input should be set to <code>true</code></li>
  <li><code>:testing</code> - boolean indicating if the <code>:testing</code> input should be set to <code>true</code></li>
</ul>
<p>If neither <code>:training</code> nor <code>:testing</code> is specified, the <code>:predicting</code> flag is set to true.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1082">view source</a></div></div><div class="public anchor" id="var-get-model-constants"><h3>get-model-constants</h3><div class="usage"><code>(get-model-constants model)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L992">view source</a></div></div><div class="public anchor" id="var-get-model-data"><h3>get-model-data</h3><div class="usage"><code>(get-model-data model dataset-name varname)</code></div><div class="doc"><div class="markdown"><p>Returns data for a given dataset and variable name. For example, <code>(get-model-data :training :x)</code>. Throws exceptions if the model doesn’t have a dataset or variable of the given name.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1027">view source</a></div></div><div class="public anchor" id="var-get-model-dataset"><h3>get-model-dataset</h3><div class="usage"><code>(get-model-dataset model dataset-or-name)</code></div><div class="doc"><div class="markdown"><p>If <code>dataset-or-name</code> is a map (assumed to contain variable-name -&gt; value), just returns the map; otherwise looks up the dataset by the provided name in the model’s associated data and returns the corresponding map of variable-name -&gt; value.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1013">view source</a></div></div><div class="public anchor" id="var-get-model-graph"><h3>get-model-graph</h3><div class="usage"><code>(get-model-graph model)</code></div><div class="doc"><div class="markdown"><p>Returns <code>model</code>’s computation graph.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1008">view source</a></div></div><div class="public anchor" id="var-get-model-input-map"><h3>get-model-input-map</h3><div class="usage"><code>(get-model-input-map model dataset-or-name)</code></div><div class="doc"><div class="markdown"><p>Returns all a map of all model graph inputs (constants and vars from <code>dataset-or-name</code>).</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1038">view source</a></div></div><div class="public anchor" id="var-get-model-optimizer"><h3>get-model-optimizer</h3><div class="usage"><code>(get-model-optimizer model)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1000">view source</a></div></div><div class="public anchor" id="var-get-model-optimizer-options"><h3>get-model-optimizer-options</h3><div class="usage"><code>(get-model-optimizer-options model)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1004">view source</a></div></div><div class="public anchor" id="var-get-model-parameters"><h3>get-model-parameters</h3><div class="usage"><code>(get-model-parameters model)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L996">view source</a></div></div><div class="public anchor" id="var-get-previous-optimizer-result"><h3>get-previous-optimizer-result</h3><div class="usage"><code>(get-previous-optimizer-result model dataset-or-name)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L988">view source</a></div></div><div class="public anchor" id="var-gru"><h3>gru</h3><div class="usage"><code>(gru operand options)</code></div><div class="doc"><div class="markdown"><p>Gated recurrent unit layer. Input, output, and options are the same as for a <code>recurrent</code> layer, with the following additional options:</p>
<ul>
  <li><code>:relevance-gate-initializer</code></li>
  <li><code>:relevance-gate-regularizer</code></li>
  <li><code>:update-gate-initializer</code></li>
  <li><code>:update-gate-regularizer</code></li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L826">view source</a></div></div><div class="public anchor" id="var-logistic"><h3>logistic</h3><div class="usage"><code>(logistic g)</code></div><div class="doc"><div class="markdown"><p>Computes <code>1 / (1 + e^-g)</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L510">view source</a></div></div><div class="public anchor" id="var-logistic-binary-classifier"><h3>logistic-binary-classifier</h3><div class="usage"><code>(logistic-binary-classifier g)</code></div><div class="doc"><div class="markdown"><p>Returns a boolean tensor representing <code>1 / (1 + e^-</code>g<code>) &gt;= 0.5</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L515">view source</a></div></div><div class="public anchor" id="var-make-binary-classifier-reporter"><h3>make-binary-classifier-reporter</h3><div class="usage"><code>(make-binary-classifier-reporter)</code></div><div class="doc"><div class="markdown"><p>Returns a reporter function for the accuracy of predictions for a binary classification problem. The returned function receives arguments [predicted actual], where <code>predicted</code> is a tensor where each element is a probability of that sample belonging to one class, and <code>actual</code> is a binary tensor of the same shape representing the true class memberships.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L919">view source</a></div></div><div class="public anchor" id="var-make-constant-initializer"><h3>make-constant-initializer</h3><div class="usage"><code>(make-constant-initializer constant)</code></div><div class="doc"><div class="markdown"><p>Returns a function that takes a shape and will return the tensor <code>constant</code> of that shape. Throws an exception if the constant does not have the shape.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L48">view source</a></div></div><div class="public anchor" id="var-make-fill-initializer"><h3>make-fill-initializer</h3><div class="usage"><code>(make-fill-initializer constant)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with <code>constant</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L42">view source</a></div></div><div class="public anchor" id="var-make-he-normal-initializer"><h3>make-he-normal-initializer</h3><div class="usage"><code>(make-he-normal-initializer)</code><code>(make-he-normal-initializer input-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values drawn from a truncated normal distribution with SD <code>sqrt(2 / m)</code>, where m is the size of the <code>input-axes</code>, either a single axis index or vector of axis indices (defaults to 1). The distribution is truncated at +/- 2 SD’s.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L169">view source</a></div></div><div class="public anchor" id="var-make-he-uniform-initializer"><h3>make-he-uniform-initializer</h3><div class="usage"><code>(make-he-uniform-initializer)</code><code>(make-he-uniform-initializer input-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values uniformly distributed in <code>[-sqrt(6 / m), sqrt(6 / m))</code>, where m is the size of the <code>input-axes</code>, either a single axis index or vector of axis indices (defaults to 1).</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L157">view source</a></div></div><div class="public anchor" id="var-make-l1-regularizer"><h3>make-l1-regularizer</h3><div class="usage"><code>(make-l1-regularizer num-examples)</code><code>(make-l1-regularizer num-examples regularization-weight)</code></div><div class="doc"><div class="markdown"><p>Returns an L1 regularizer:</p>
<p><code>cost + regularization-weight / 2m * (sum of absolute value of all elements in parameter tensor)</code></p>
<p>where <code>m</code> is the number of training examples included in the cost calculation.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L381">view source</a></div></div><div class="public anchor" id="var-make-l2-regularizer"><h3>make-l2-regularizer</h3><div class="usage"><code>(make-l2-regularizer num-examples)</code><code>(make-l2-regularizer num-examples regularization-weight)</code></div><div class="doc"><div class="markdown"><p>Returns an L2 regularizer:</p>
<p><code>cost + regularization-weight / 2m * (sum of squares of all elements in parameter tensor)</code></p>
<p>where <code>m</code> is the number of training examples included in the cost calculation.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L360">view source</a></div></div><div class="public anchor" id="var-make-lecun-normal-initializer"><h3>make-lecun-normal-initializer</h3><div class="usage"><code>(make-lecun-normal-initializer)</code><code>(make-lecun-normal-initializer input-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values drawn from a truncated normal distribution with SD <code>sqrt(1 / m)</code>, where m is the size of the <code>input-axes</code>, either a single axis index or vector of axis indices (defaults to 1). The distribution is truncated at +/- 2 SD’s.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L145">view source</a></div></div><div class="public anchor" id="var-make-lecun-uniform-initializer"><h3>make-lecun-uniform-initializer</h3><div class="usage"><code>(make-lecun-uniform-initializer)</code><code>(make-lecun-uniform-initializer input-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values uniformly distributed in <code>[-sqrt(3 / m), sqrt(3 / m))</code>, where m is the size of the <code>input-axes</code>, either a single axis index or vector of axis indices (defaults to 1).</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L133">view source</a></div></div><div class="public anchor" id="var-make-model"><h3>make-model</h3><div class="usage"><code>(make-model &amp; {:as options})</code></div><div class="doc"><div class="markdown"><p>Cosntructs a model, given:</p>
<ul>
  <li><code>:data</code> (required) - A map of maps (dataset-name -&gt; variable-name -&gt; data). The common case is to have  multiple datasets for different uses (e.g. <code>:training</code>, <code>:dev</code>, and <code>:test</code>), each with the same  variables (e.g. <code>:x</code> and <code>:y</code>).</li>
  <li><code>:graph</code> (required) - A computation graph for the model.</li>
  <li><code>:optimizer</code> (optional, defaults to gradient-descent-optimizer)</li>
  <li><code>:optimizer-options</code> (optional) - Map of options to pass to <code>:optimizer</code></li>
  <li><code>:constants</code> (optional) - A map of name to value for graph inputs that do not change (i.e. that are  constant cross datasets).</li>
  <li><code>:parameters</code> (optional) - A map of name to value for graph parameters. This can be excluded if all  parameters have initialization functions specified.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L940">view source</a></div></div><div class="public anchor" id="var-make-multiclass-accuracy-reporter"><h3>make-multiclass-accuracy-reporter</h3><div class="usage"><code>(make-multiclass-accuracy-reporter)</code><code>(make-multiclass-accuracy-reporter options)</code></div><div class="doc"><div class="markdown"><p>Returns a reporter function for the accuracy of predictions for a multi-class classification problem. The returned function receives arguments [predicted actual], where <code>predicted</code> is a tensor containing probabilities for each class along one axis and samples along all other axes. <code>actual</code> is a binary tensor of the same structure containing the true class memberships represented in one-hot form. <code>options</code> can include:</p>
<ul>
  <li><code>:class-axis</code>: the index of the axis spanning classes</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L893">view source</a></div></div><div class="public anchor" id="var-make-normal-random-initializer"><h3>make-normal-random-initializer</h3><div class="usage"><code>(make-normal-random-initializer)</code><code>(make-normal-random-initializer mean stdev)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with random values normally distributed around <code>mean</code> with standard deviation <code>stdev</code>. <code>mean</code> and <code>stdev</code> can be either numbers or functions that return the numbers when applied to the shape.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L75">view source</a></div></div><div class="public anchor" id="var-make-truncated-random-initializer"><h3>make-truncated-random-initializer</h3><div class="usage"><code>(make-truncated-random-initializer)</code><code>(make-truncated-random-initializer mean stdev)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with random values normally distributed around <code>mean</code> with standard deviation <code>stdev</code> but with no values &gt;2 SD’s from the mean. <code>mean</code> and <code>stdev</code> can be either numbers or functions that return the numbers when applied to the shape.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L88">view source</a></div></div><div class="public anchor" id="var-make-uniform-random-initializer"><h3>make-uniform-random-initializer</h3><div class="usage"><code>(make-uniform-random-initializer)</code><code>(make-uniform-random-initializer min max)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with random values uniformly distributed in [min, max). <code>min</code> and <code>max</code> can be either numbers or functions that when applied to the shape will return numbers.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L62">view source</a></div></div><div class="public anchor" id="var-make-variance-scaling-initializer"><h3>make-variance-scaling-initializer</h3><div class="usage"><code>(make-variance-scaling-initializer)</code><code>(make-variance-scaling-initializer scale)</code><code>(make-variance-scaling-initializer scale axis)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with random values normally distributed around 0. The standard deviation will be <code>sqrt(scale / axis-sum)</code> where <code>axis-sum</code> is the sum of the sizes of all axes in <code>axis</code>. <code>axis</code> can be either a vector of axes or an integer indicating a single axis. The distribution is truncted such that no values &gt;2 SD’s from 0 are included.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L111">view source</a></div></div><div class="public anchor" id="var-make-xavier-normal-initializer"><h3>make-xavier-normal-initializer</h3><div class="usage"><code>(make-xavier-normal-initializer)</code><code>(make-xavier-normal-initializer input-axes output-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values drawn from a truncated normal distribution with SD <code>sqrt(2 / (m + n))</code>, where m and n are the sizes of the <code>input-axes</code> and <code>output-axes</code>, respectively (defaults to 1 and 0). The distribution is truncated at +/- 2 SD’s.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L193">view source</a></div></div><div class="public anchor" id="var-make-xavier-uniform-initializer"><h3>make-xavier-uniform-initializer</h3><div class="usage"><code>(make-xavier-uniform-initializer)</code><code>(make-xavier-uniform-initializer input-axes output-axes)</code></div><div class="doc"><div class="markdown"><p>Returns a function that when applied to a shape will return a tensor of that shape filled with values uniformly distributed in <code>[-sqrt(6 / (m + n)), sqrt(6 / (m + n)))</code>, where m and n are the sizes of the <code>input-axes</code> and <code>output-axes</code>, respectively (defaults to 1 and 0).</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L181">view source</a></div></div><div class="public anchor" id="var-max-pooling2d"><h3>max-pooling2d</h3><div class="usage"><code>(max-pooling2d nd options)</code></div><div class="doc"><div class="markdown"><p>Returns a new tensor containing the maximum elements of <code>nd</code> in a window sliding along two dimensions. <code>nd</code> must a tensor of shape [m, height, width, channels]. Options include:</p>
<ul>
  <li><code>:pool-size</code> (required) - [height, width] of the sliding window</li>
  <li><code>:strides</code> (optional, defaults to <code>:pool-size</code>) - the [vertical, horizontal] step sizes to use when sliding the window.</li>
  <li><code>:padding</code> (optional) - an argument accepted by <code>pad-with</code>.</li>
</ul>
<p>The returned tensor is of shape [m, floor((height + vertical-padding - pool-height + 1) / vertical-stride), floor((width + horizontal-padding - pool-width + 1) / horizontal-stride), channels]. For a given slice through the first dimension (typically a training example) and channel, each (i, j) in the result is the maximum element in ((k * vertical-stride)…(k * vertical-stride + pool-height), (l * horizontal-stride)…(l * horizontal-stride + pool-width)) from <code>nd</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L636">view source</a></div></div><div class="public anchor" id="var-mean"><h3>mean</h3><div class="usage"><code>(mean g)</code><code>(mean g options)</code></div><div class="doc"><div class="markdown"><p>Calculates the arithmetic mean of <code>g</code> along some axes/axes. <code>options</code> can include:</p>
<ul>
  <li><code>:axis</code> (optional) - a scalar or vector indicating the axes across which the mean should be taken; if  ommitted, the mean of all elements in <code>g</code> will be returned.</li>
  <li><code>:collapse</code> (optional) - boolean indicating if the dimensions specified in <code>:axis</code> should be removed.  If false, dimensions will be maintained with a size of 1.</li>
</ul></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L460">view source</a></div></div><div class="public anchor" id="var-normalize"><h3>normalize</h3><div class="usage"><code>(normalize g)</code><code>(normalize g options)</code></div><div class="doc"><div class="markdown"><p>Calculates baseline-corrected-g / variance, where baseline-correcred-g is g - mean(g), and variance is sum(base-line-corrected-g^2) / size(baseline-corrected-g). Options can include <code>:axis</code>, a single axis or a vector of axes over which to perform the <code>sum</code>, <code>size</code>, and <code>mean</code> operations. If <code>:axis</code> is not provided, normalization will be done over the entire tensor <code>g</code>. The returned result is the same shape as <code>g</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L479">view source</a></div></div><div class="public anchor" id="var-ones-initializer"><h3>ones-initializer</h3><div class="usage"><code>(ones-initializer shape)</code></div><div class="doc"><div class="markdown"><p>Returns a tensor of <code>shape</code> filled with 1’s.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L37">view source</a></div></div><div class="public anchor" id="var-recurrent"><h3>recurrent</h3><div class="usage"><code>(recurrent operand options)</code></div><div class="doc"><div class="markdown"><p>Simple recurrent layer. <code>operand</code> must be a tensor of shape <code>[example-count example-size timepoint-count]</code>. Required options are:</p>
<ul>
  <li><code>:hidden-units</code> - size of hidden state</li>
  <li><code>:output-units</code> - output dimensionality</li>
</ul>
<p>Additional options are:</p>
<ul>
  <li><code>:initializer</code> - weight/bias initializer for the internal <code>dense</code> layer</li>
  <li><code>:W-initializer</code> - weight initializer for the internal <code>dnese</code> layer</li>
  <li><code>:b-initializer</code> - bias initializer for the internal <code>dense</code> layer</li>
  <li><code>:state-initializer</code> - initializer for the hidden state matrix</li>
  <li><code>:regularizer</code> - regularizer for output and recurrent dense layer (fallback if <code>:output-regularizer</code> or <code>:recurrent-regularizer</code> isn’t provided)</li>
  <li><code>:output-regularizer</code> - regularizer for the output <code>dense</code> layer</li>
  <li><code>:recurrent-regularizer</code> - regularizer for the recurrent <code>dense</code> layer</li>
  <li><code>recurrent-activation</code> - activation function for the recurrent connection</li>
  <li><code>:stateful</code> (default <code>false</code>) - boolean indicating if state should be maintained between iterations</li>
  <li><code>:mask</code> - boolean matrix of shape <code>[example-count timepoint-count]</code>. If provided, then state and output for a given example is updated at all timepoints where the <code>:mask</code> is true (1.0). Where the <code>:mask</code> is false (0.0), the previous state and output value are maintained.</li>
</ul>
<p>The output is of shape <code>[example-count output-units timepoint-count]</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L759">view source</a></div></div><div class="public anchor" id="var-regularize"><h3>regularize</h3><div class="usage"><code>(regularize g)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L409">view source</a></div></div><div class="public anchor" id="var-relu"><h3>relu</h3><div class="usage"><code>(relu g)</code></div><div class="doc"><div class="markdown"><p>Computes <code>min(g, 0)</code>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L502">view source</a></div></div><div class="public anchor" id="var-reserved-node-names"><h3>reserved-node-names</h3><div class="usage"></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L938">view source</a></div></div><div class="public anchor" id="var-sigmoid-cross-entropy"><h3>sigmoid-cross-entropy</h3><div class="usage"><code>(sigmoid-cross-entropy predicted actual)</code></div><div class="doc"><div class="markdown"><p>Computes the sum over all elements of the result of <code>max(predicted, 0) - predicted * actual + log (1 + e^-abs(predicted))</code>. This is roughly equivalent to the total logistic loss <code>actual * -log(sigmoid(predicted)) + (1 - actual) * -log(1 - sigmoid(predicted))</code>, but with some modifications for numerical stability. Based on the TensorFlow implementation (<a href="https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)">https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits)</a>.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L419">view source</a></div></div><div class="public anchor" id="var-softmax"><h3>softmax</h3><div class="usage"><code>(softmax operand)</code><code>(softmax operand options)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L726">view source</a></div></div><div class="public anchor" id="var-train-model"><h3>train-model</h3><div class="usage"><code>(train-model model)</code><code>(train-model model iterations)</code><code>(train-model model dataset-or-name iterations)</code></div><div class="doc"><div class="markdown"><p>Fits <code>model</code> to data in <code>dataset-or-name</code> by running the model’s optimizer for <code>iterations</code> iterations. Defaults to running 1 iteration on the <code>:training</code> data. Blocks until complete.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1146">view source</a></div></div><div class="public anchor" id="var-train-model-async"><h3>train-model-async</h3><div class="usage"><code>(train-model-async model)</code><code>(train-model-async model iterations-or-dataset-or-name)</code><code>(train-model-async model dataset-or-name iterations)</code></div><div class="doc"><div class="markdown"><p>Fits <code>model</code> to data in <code>dataset-or-name</code> (default <code>:training</code>) by running the model’s optimizer for <code>iterations</code> (defaults to infinite). Launches optimization in a new thread and immediately returns a 0-arity function, <code>stop</code>, that when called will immediately return the trained model from the last complete iteration and terminate the optimization process after the next iteration is complete.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L1157">view source</a></div></div><div class="public anchor" id="var-update-model"><h3>update-model</h3><div class="usage"><code>(update-model model &amp; {:as updates})</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L980">view source</a></div></div><div class="public anchor" id="var-update-prev-optimizer-results"><h3>update-prev-optimizer-results</h3><div class="usage"><code>(update-prev-optimizer-results model dataset-or-name optimizer-result)</code></div><div class="doc"><div class="markdown"></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L984">view source</a></div></div><div class="public anchor" id="var-zeros-initializer"><h3>zeros-initializer</h3><div class="usage"><code>(zeros-initializer shape)</code></div><div class="doc"><div class="markdown"><p>Returns a tensor of <code>shape</code> filled with 0’s.</p></div></div><div class="src-link"><a href="https://github.com/cguenthner/neurojure/blob/43c2f694c3aa7f898e5f42181371ca2e2005e4dd/src/neurojure/core.clj#L32">view source</a></div></div></div></body></html>